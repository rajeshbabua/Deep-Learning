{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import nltk # natural language processing\nfrom nltk.stem import PorterStemmer #stemming words\nfrom nltk.tokenize import word_tokenize,sent_tokenize # tokenizing into words and sentences\nfrom nltk.corpus import stopwords #stopwords in english\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))\n\n",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['testData.tsv', 'sampleSubmission.csv', 'labeledTrainData.tsv', 'unlabeledTrainData.tsv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "lbl_train = pd.read_csv('../input/labeledTrainData.tsv',  sep= '\\t', header = 0)\ntest_d =    pd.read_csv('../input/testData.tsv',  sep= '\\t', header = 0)\nlbl_train.size,test_d.size\n",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "(75000, 50000)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f61ed02caa87ac53bbfd319a8784ee5dc915c31e"
      },
      "cell_type": "code",
      "source": "total=lbl_train['review'].size + test_d[\"review\"].size\ntotal    ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "50000"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "da5f2477d046b767dcda0936ac192f07b394ea53"
      },
      "cell_type": "code",
      "source": "###########data preprocessing\nfrom bs4 import BeautifulSoup\nimport re\ndef raw_rev(rev):\n    r_tag = BeautifulSoup(rev).get_text()                  ###removing html tags\n    reg = re.sub(\"[^a-z/A-Z ]\",\" \",r_tag)                  ###excluding special characters\n    normal = reg.lower()                                   ##normalizing text\n    token = word_tokenize(normal)                          #####tokenizng\n    stop_words = stopwords.words(\"english\")                ### considering stopwords in english\n    fi = []                                                  ###assigned a list\n    [fi.append(w) for w in token if w not in stop_words]   ###creating a list excluding stopwords\n    t =\" \".join(fi)                                   ####joining words bac\n    return (t)",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "14973418187e7b743b8b98604e0d1dd22ee0a6a8",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "#############filtered text\nclean_train = []\nclean_test = []\nfor i in range (0,lbl_train[\"review\"].size):\n     clean_train.append(raw_rev(lbl_train[\"review\"][i]))\nfor j in range(0,test_d[\"review\"].size):\n     clean_test.append(raw_rev(test_d[\"review\"][j]))",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35f343409b432dfbd4cc2197dac95d72978224f6"
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.text import one_hot\none_h_train = [one_hot(review,2000) for review in clean_train]\none_h_test = [one_hot(review,2000) for review in clean_test]\nprint(one_h_train[0]), print(one_h_test[0])",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[825, 958, 82, 836, 650, 1034, 1957, 303, 1148, 599, 1733, 381, 1733, 1124, 461, 1882, 144, 1968, 1214, 506, 1281, 1998, 1022, 1215, 461, 465, 365, 225, 1828, 1838, 1124, 1523, 938, 1523, 696, 670, 1815, 958, 1903, 1164, 1182, 1976, 669, 1230, 836, 1480, 1029, 1230, 975, 16, 1704, 64, 178, 128, 1832, 1733, 1452, 850, 1033, 975, 1675, 442, 836, 875, 958, 632, 1115, 132, 737, 1380, 836, 1065, 1437, 209, 1188, 836, 1816, 737, 1829, 1467, 1816, 200, 1998, 51, 1852, 696, 670, 68, 1725, 1348, 299, 199, 411, 1822, 1949, 354, 291, 1746, 1417, 1822, 1534, 1592, 848, 836, 1089, 178, 733, 836, 1051, 1418, 1921, 354, 291, 133, 201, 95, 125, 1654, 1677, 64, 475, 1654, 461, 1309, 836, 1957, 1112, 1022, 304, 442, 836, 1677, 1694, 1063, 1028, 1909, 484, 1949, 975, 1850, 1938, 1366, 742, 1548, 701, 1750, 178, 1949, 1012, 1949, 632, 1391, 721, 1447, 1778, 1279, 1028, 1373, 1513, 842, 1729, 1838, 1309, 93, 1188, 125, 442, 836, 721, 810, 1013, 1860, 125, 975, 411, 1762, 1307, 167, 1704, 1672, 836, 982, 783, 1188, 1452, 850, 1033, 1966, 721, 1962, 125, 1057, 1799, 85, 1828, 824, 1224, 1628, 1672, 1256, 824, 1654, 125, 1543, 395, 1400, 1050, 1654, 337, 295, 226, 51, 1446, 506, 721, 146, 248, 1833, 579]\n[723, 670, 1277, 1490, 1941, 237, 332, 988, 1884, 857, 998, 290, 517, 988, 271, 1931, 1769, 1813, 70, 670, 562, 911, 947, 353, 1649, 418, 1067, 1944, 1778, 1740, 1282, 1573, 880, 953, 627, 848, 1369, 442, 848, 423, 173, 848, 1590, 981, 848, 734, 723, 1024, 638, 469, 1850, 670, 1166, 1467, 1231, 333, 949, 817, 1626, 1850, 43, 537, 1605, 1043, 58, 128, 1966, 534, 742, 773, 1982, 422]\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 62,
          "data": {
            "text/plain": "(None, None)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "778fcb0a556641afa6da0b6c7b8e58c1272ccfbc"
      },
      "cell_type": "code",
      "source": "from keras.preprocessing import sequence, text\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer, text_to_word_sequence\n\nX_train = sequence.pad_sequences(one_h_train, maxlen=350)\nX_test = sequence.pad_sequences(one_h_test, maxlen=350)\nprint(X_train.shape,X_test.shape)\n\n",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(25000, 350) (25000, 350)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2b891d7db37546a7f9b84f87fbba22a30a9a31b3"
      },
      "cell_type": "code",
      "source": "x_t= X_train[:20000]\nx_l = lbl_train.sentiment[:20000]\nvalid_t= X_train[20000:]\nvalid_l =lbl_train.sentiment[20000:]\n",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9ce979bb56cd351b52d078254669c5f37d62933d"
      },
      "cell_type": "code",
      "source": "x_l.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6e2e2296682ee042069ba77d5626530c6aaf12b8"
      },
      "cell_type": "code",
      "source": "####word cloud\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom wordcloud import WordCloud\nwc= WordCloud(height = 500, width = 1000).generate(\"\".join(fea))\nplt.figure(figsize=(10,10))\nplt.imshow(wc, interpolation= 'bilinear')\nplt.axis(\"off\")\nplt.margins(x=0,y=0)\nplt.show",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d08da6cb1805ceb8645fa99db514036412d2fdb"
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom tensorflow import keras\nfrom keras. layers import Dropout,Dense,Flatten\nfrom keras.models import Sequential\nvocab=10000\nmodel = keras.Sequential()\nmodel.add(keras.layers.Embedding(vocab,400,input_length=350))\nmodel.add(keras.layers.LSTM(400, return_sequences =True))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.Flatten())\n#model.add(keras.layers.Dense(10000,activation = \"softmax\"))\nmodel.add(keras.layers.Dense(1,activation = \"sigmoid\"))\n\n\n",
      "execution_count": 53,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8ad32c3a9c3c88eb69f9993f9389107794ff6ce3"
      },
      "cell_type": "code",
      "source": "model.summary()",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_7 (Embedding)      (None, 350, 400)          4000000   \n_________________________________________________________________\nlstm_7 (LSTM)                (None, 350, 400)          1281600   \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 350, 400)          0         \n_________________________________________________________________\nflatten_6 (Flatten)          (None, 140000)            0         \n_________________________________________________________________\ndense_12 (Dense)             (None, 1)                 140001    \n=================================================================\nTotal params: 5,421,601\nTrainable params: 5,421,601\nNon-trainable params: 0\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9c9fe30950c3cd1fe66523f1b21a0d944cc26fcc"
      },
      "cell_type": "code",
      "source": "model.compile(optimizer=tf.train.AdamOptimizer(), loss = 'binary_crossentropy', metrics= ['accuracy'])",
      "execution_count": 55,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ace6920c10268dddc3aaf40c24070ce6ccacf9da"
      },
      "cell_type": "code",
      "source": "###training\ntraining= model.fit(X_train,lbl_train.sentiment, epochs=10, batch_size = 500,verbose = 1)",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/10\n25000/25000 [==============================] - 149s 6ms/step - loss: 0.6189 - acc: 0.6406\nEpoch 2/10\n25000/25000 [==============================] - 144s 6ms/step - loss: 0.3952 - acc: 0.8236\nEpoch 3/10\n25000/25000 [==============================] - 144s 6ms/step - loss: 0.3554 - acc: 0.8438\nEpoch 4/10\n25000/25000 [==============================] - 144s 6ms/step - loss: 0.3346 - acc: 0.8535\nEpoch 5/10\n25000/25000 [==============================] - 145s 6ms/step - loss: 0.3020 - acc: 0.8710\nEpoch 6/10\n25000/25000 [==============================] - 146s 6ms/step - loss: 0.2709 - acc: 0.8862\nEpoch 7/10\n25000/25000 [==============================] - 146s 6ms/step - loss: 0.2308 - acc: 0.9059\nEpoch 8/10\n25000/25000 [==============================] - 146s 6ms/step - loss: 0.1827 - acc: 0.9287\nEpoch 9/10\n25000/25000 [==============================] - 145s 6ms/step - loss: 0.1394 - acc: 0.9472\nEpoch 10/10\n25000/25000 [==============================] - 146s 6ms/step - loss: 0.1020 - acc: 0.9636\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c0b5515214318df6781af72a7e56e34e06682c57"
      },
      "cell_type": "code",
      "source": "wa = model.predict(X_test)\nwa1 = wa>0.5",
      "execution_count": 57,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0988bea8d75ce62b521aa818896a3bc23f66f779"
      },
      "cell_type": "code",
      "source": "wa[0]\ntest_d[\"sentiment\"] = test_d[\"id\"].map(lambda r: 1 if int(r.strip('\"').split(\"_\")[1]) >= 5 else 0)\nans = test_d[\"sentiment\"]",
      "execution_count": 58,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "76adb4eeffb797185893b643c17ec76b31e89809"
      },
      "cell_type": "code",
      "source": "ans",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 59,
          "data": {
            "text/plain": "0        1\n1        0\n2        0\n3        0\n4        1\n5        1\n6        0\n7        0\n8        0\n9        1\n10       0\n11       1\n12       0\n13       1\n14       0\n15       0\n16       0\n17       0\n18       1\n19       0\n20       0\n21       0\n22       1\n23       0\n24       1\n25       0\n26       0\n27       0\n28       0\n29       0\n        ..\n24970    1\n24971    1\n24972    0\n24973    0\n24974    0\n24975    0\n24976    1\n24977    1\n24978    1\n24979    1\n24980    1\n24981    1\n24982    1\n24983    1\n24984    1\n24985    0\n24986    1\n24987    1\n24988    0\n24989    0\n24990    0\n24991    0\n24992    0\n24993    1\n24994    0\n24995    1\n24996    1\n24997    0\n24998    1\n24999    1\nName: sentiment, Length: 25000, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e4d4a6e0c268ffa38bcc92a9f5fd2f4b7236f872"
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import f1_score, confusion_matrix\nprint('F1-score: {0}'.format(f1_score(wa1, ans)))\nprint('Confusion matrix:')\nconfusion_matrix(wa1, ans)",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": "F1-score: 0.7793629860528314\nConfusion matrix:\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 60,
          "data": {
            "text/plain": "array([[9728, 2749],\n       [2772, 9751]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "675aaccb609bb5e56559df2214f2cfe98c9715d2"
      },
      "cell_type": "code",
      "source": "data = {\"id\":test_d[\"id\"], \"sentiment\":ans}\nsubmission = pd.DataFrame(data, columns =['id', 'sentiment'])\nsubmission",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 61,
          "data": {
            "text/plain": "             id  sentiment\n0      12311_10          1\n1        8348_2          0\n2        5828_4          0\n3        7186_2          0\n4       12128_7          1\n5        2913_8          1\n6        4396_1          0\n7         395_2          0\n8       10616_1          0\n9        9074_9          1\n10       9252_3          0\n11       9896_9          1\n12        574_4          0\n13      11182_8          1\n14      11656_4          0\n15       2322_4          0\n16       8703_1          0\n17       7483_1          0\n18      6007_10          1\n19      12424_4          0\n20       4672_1          0\n21      10841_3          0\n22       8954_7          1\n23       7392_1          0\n24      10288_8          1\n25       5343_4          0\n26       4950_1          0\n27       9257_4          0\n28       8689_3          0\n29       4480_2          0\n...         ...        ...\n24970   6857_10          1\n24971   11091_8          1\n24972    4167_2          0\n24973     679_4          0\n24974   10147_1          0\n24975    6875_1          0\n24976    923_10          1\n24977    6200_8          1\n24978    7208_8          1\n24979    5363_8          1\n24980    4067_8          1\n24981    1773_7          1\n24982   1498_10          1\n24983  10497_10          1\n24984   3444_10          1\n24985     588_2          0\n24986    9678_9          1\n24987    1983_9          1\n24988    5012_3          0\n24989   12240_2          0\n24990    5071_2          0\n24991    5078_2          0\n24992   10069_3          0\n24993    7407_8          1\n24994    7207_1          0\n24995   2155_10          1\n24996     59_10          1\n24997    2531_1          0\n24998    7772_8          1\n24999  11465_10          1\n\n[25000 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12311_10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8348_2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5828_4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7186_2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12128_7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2913_8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4396_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>395_2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10616_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9074_9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9252_3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>9896_9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>574_4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>11182_8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>11656_4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2322_4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>8703_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>7483_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>6007_10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>12424_4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>4672_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>10841_3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>8954_7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>7392_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>10288_8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>5343_4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>4950_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>9257_4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>8689_3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>4480_2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>24970</th>\n      <td>6857_10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24971</th>\n      <td>11091_8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24972</th>\n      <td>4167_2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24973</th>\n      <td>679_4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24974</th>\n      <td>10147_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24975</th>\n      <td>6875_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24976</th>\n      <td>923_10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24977</th>\n      <td>6200_8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24978</th>\n      <td>7208_8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24979</th>\n      <td>5363_8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24980</th>\n      <td>4067_8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24981</th>\n      <td>1773_7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24982</th>\n      <td>1498_10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24983</th>\n      <td>10497_10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24984</th>\n      <td>3444_10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24985</th>\n      <td>588_2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24986</th>\n      <td>9678_9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24987</th>\n      <td>1983_9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24988</th>\n      <td>5012_3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24989</th>\n      <td>12240_2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24990</th>\n      <td>5071_2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24991</th>\n      <td>5078_2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24992</th>\n      <td>10069_3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24993</th>\n      <td>7407_8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24994</th>\n      <td>7207_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24995</th>\n      <td>2155_10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24996</th>\n      <td>59_10</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24997</th>\n      <td>2531_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24998</th>\n      <td>7772_8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24999</th>\n      <td>11465_10</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>25000 rows Ã— 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
